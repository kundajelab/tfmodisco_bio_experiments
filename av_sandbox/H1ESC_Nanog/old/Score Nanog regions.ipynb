{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is set up for 1d convolutions where examples\n",
    "#have dimensions (len, num_channels)\n",
    "#the channel axis is the axis for one-hot encoding.\n",
    "def one_hot_encode_along_channel_axis(sequence):\n",
    "    to_return = np.zeros((len(sequence),4), dtype=np.int8)\n",
    "    seq_to_one_hot_fill_in_array(zeros_array=to_return,\n",
    "                                 sequence=sequence, one_hot_axis=1)\n",
    "    return to_return\n",
    "\n",
    "def seq_to_one_hot_fill_in_array(zeros_array, sequence, one_hot_axis):\n",
    "    assert one_hot_axis==0 or one_hot_axis==1\n",
    "    if (one_hot_axis==0):\n",
    "        assert zeros_array.shape[1] == len(sequence)\n",
    "    elif (one_hot_axis==1): \n",
    "        assert zeros_array.shape[0] == len(sequence)\n",
    "    #will mutate zeros_array\n",
    "    for (i,char) in enumerate(sequence):\n",
    "        if (char==\"A\" or char==\"a\"):\n",
    "            char_idx = 0\n",
    "        elif (char==\"C\" or char==\"c\"):\n",
    "            char_idx = 1\n",
    "        elif (char==\"G\" or char==\"g\"):\n",
    "            char_idx = 2\n",
    "        elif (char==\"T\" or char==\"t\"):\n",
    "            char_idx = 3\n",
    "        elif (char==\"N\" or char==\"n\"):\n",
    "            continue #leave that pos as all 0's\n",
    "        else:\n",
    "            raise RuntimeError(\"Unsupported character: \"+str(char))\n",
    "        if (one_hot_axis==0):\n",
    "            zeros_array[char_idx,i] = 1\n",
    "        elif (one_hot_axis==1):\n",
    "            zeros_array[i,char_idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8307, 1000, 4)\n"
     ]
    }
   ],
   "source": [
    "import pyfasta\n",
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "file_with_regions = \"1kb_around_summit_H1-hESC-NANOG-human-ENCSR000BMT-optimal_idr.bed\"\n",
    "test_chromosomes = [\"chr1\"]\n",
    "\n",
    "fasta_data_source = \"/mnt/data/annotations/by_organism/human/hg19.GRCh37/hg19.genome.fa\"\n",
    "f = pyfasta.Fasta(fasta_data_source)\n",
    "\n",
    "fasta_sequences = []\n",
    "\n",
    "for line in gzip.open(file_with_regions, \"rb\"):\n",
    "    line = line.rstrip()\n",
    "    chrom,start,end = line.split(\"\\t\")\n",
    "    start,end = int(start),int(end)\n",
    "    the_seq = f[chrom][start:end]\n",
    "    fasta_sequences.append(the_seq)\n",
    "\n",
    "onehot_fasta = np.array([one_hot_encode_along_channel_axis(x) for x in fasta_sequences])\n",
    "print(onehot_fasta.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/users/avanti/anaconda2/lib/python2.7/site-packages/scipy/sparse/lil.py:19: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _csparsetools\n",
      "/users/avanti/anaconda2/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:165: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._shortest_path import shortest_path, floyd_warshall, dijkstra,\\\n",
      "/users/avanti/anaconda2/lib/python2.7/site-packages/scipy/sparse/csgraph/_validation.py:5: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._tools import csgraph_to_dense, csgraph_from_dense,\\\n",
      "/users/avanti/anaconda2/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:167: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._traversal import breadth_first_order, depth_first_order, \\\n",
      "/users/avanti/anaconda2/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:169: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._min_spanning_tree import minimum_spanning_tree\n",
      "/users/avanti/anaconda2/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:170: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._reordering import reverse_cuthill_mckee, maximum_bipartite_matching, \\\n",
      "/users/avanti/anaconda2/lib/python2.7/site-packages/scipy/linalg/basic.py:17: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._solve_toeplitz import levinson\n",
      "/users/avanti/anaconda2/lib/python2.7/site-packages/scipy/linalg/__init__.py:207: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._decomp_update import *\n",
      "/users/avanti/anaconda2/lib/python2.7/site-packages/scipy/special/__init__.py:640: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._ufuncs import *\n",
      "/users/avanti/anaconda2/lib/python2.7/site-packages/scipy/special/_ellip_harm.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._ellip_harm_2 import _ellipsoid, _ellipsoid_norm\n",
      "/users/avanti/anaconda2/lib/python2.7/site-packages/scipy/interpolate/_bsplines.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _bspl\n",
      "/users/avanti/anaconda2/lib/python2.7/site-packages/scipy/spatial/__init__.py:95: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .ckdtree import *\n",
      "/users/avanti/anaconda2/lib/python2.7/site-packages/scipy/spatial/__init__.py:96: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .qhull import *\n",
      "/users/avanti/anaconda2/lib/python2.7/site-packages/scipy/spatial/_spherical_voronoi.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _voronoi\n",
      "/users/avanti/anaconda2/lib/python2.7/site-packages/scipy/spatial/distance.py:122: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _hausdorff\n",
      "/users/avanti/anaconda2/lib/python2.7/site-packages/scipy/ndimage/measurements.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _ni_label\n",
      "WARNING:tensorflow:From /users/avanti/anaconda2/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras.models import model_from_json\n",
    "\n",
    "model_h5 = \"record_1_model_HcVec_modelWeights.h5\"\n",
    "model_json = \"record_1_model_HcVec_modelJson.json\"\n",
    "the_model = model_from_json(open(model_json).read())\n",
    "the_model.load_weights(model_h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonlinear_mxts_mode is set to: DeepLIFT_GenomicsDefault\n",
      "For layer 2 the preceding linear layer is 0 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "For layer 5 the preceding linear layer is 3 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "For layer 8 the preceding linear layer is 6 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "For layer 13 the preceding linear layer is 11 of type Dense;\n",
      "In accordance with nonlinear_mxts_modeDeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to RevealCancel\n",
      "Heads-up: I assume sigmoid is the output layer, not an intermediate one; if it's an intermediate layer then please bug me and I will implement the grad func\n",
      "For layer 16 the preceding linear layer is 15 of type Dense;\n",
      "In accordance with nonlinear_mxts_modeDeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to RevealCancel\n"
     ]
    }
   ],
   "source": [
    "import deeplift\n",
    "from deeplift.conversion import kerasapi_conversion as kc\n",
    "\n",
    "deeplift_model =\\\n",
    "    kc.convert_model_from_saved_files(\n",
    "        h5_file=model_h5, json_file=model_json) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 reference seqs generated\n",
      "8000 reference seqs generated\n",
      "12000 reference seqs generated\n",
      "16000 reference seqs generated\n",
      "20000 reference seqs generated\n",
      "24000 reference seqs generated\n",
      "28000 reference seqs generated\n",
      "32000 reference seqs generated\n",
      "36000 reference seqs generated\n",
      "40000 reference seqs generated\n",
      "44000 reference seqs generated\n",
      "48000 reference seqs generated\n",
      "52000 reference seqs generated\n",
      "56000 reference seqs generated\n",
      "60000 reference seqs generated\n",
      "64000 reference seqs generated\n",
      "68000 reference seqs generated\n",
      "72000 reference seqs generated\n",
      "76000 reference seqs generated\n",
      "80000 reference seqs generated\n",
      "One hot encoding sequences...\n",
      "One hot encoding done...\n",
      "Done 0\n",
      "Done 4000\n",
      "Done 8000\n",
      "Done 12000\n",
      "Done 16000\n",
      "Done 20000\n",
      "Done 24000\n",
      "Done 28000\n",
      "Done 32000\n",
      "Done 36000\n",
      "Done 40000\n",
      "Done 44000\n",
      "Done 48000\n",
      "Done 52000\n",
      "Done 56000\n",
      "Done 60000\n",
      "Done 64000\n",
      "Done 68000\n",
      "Done 72000\n",
      "Done 76000\n",
      "Done 80000\n"
     ]
    }
   ],
   "source": [
    "from deeplift.util import get_hypothetical_contribs_func_onehot\n",
    "from deeplift.util import get_shuffle_seq_ref_function\n",
    "from deeplift.dinuc_shuffle import dinuc_shuffle\n",
    "\n",
    "multipliers_func = deeplift_model.get_target_multipliers_func(\n",
    "                            find_scores_layer_idx=0)\n",
    "\n",
    "hypothetical_contribs_func = get_hypothetical_contribs_func_onehot(multipliers_func)\n",
    "hypothetical_contribs_many_refs_func = get_shuffle_seq_ref_function(\n",
    "    score_computation_function=hypothetical_contribs_func,\n",
    "    shuffle_func=dinuc_shuffle,\n",
    "    one_hot_func=lambda x: np.array([one_hot_encode_along_channel_axis(seq)\n",
    "                                     for seq in x]))\n",
    "num_refs_per_seq=10\n",
    "hypothetical_contribs = hypothetical_contribs_many_refs_func(\n",
    "            task_idx=0,\n",
    "            input_data_sequences=fasta_sequences,\n",
    "            num_refs_per_seq=num_refs_per_seq,\n",
    "            batch_size=50,\n",
    "            progress_update=4000,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revcomp = {\"A\": \"T\", \"C\": \"G\", \"G\": \"C\", \"T\": \"A\"}\n",
    "reverse_fasta_sequences = [\"\".join(revcomp[x] for x in seq)\n",
    "                           for seq in fasta_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
