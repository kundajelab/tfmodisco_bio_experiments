{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RELA SNP scoring run #1 Sep 14 2018\n",
    "\n",
    "- examine the bQTL SNPs from bQTL paper for SPI1 (mmc2.xlsx, SPI1 tab)\n",
    "- take first full entries of smallest pvals\n",
    "- plot bQTL SNP distance from nearest modisco seqlets supporting a pattern vs -log10(pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 7001 on context None\n",
      "Mapped name None to device cuda0: GeForce GTX TITAN X (0000:08:00.0)\n",
      "2018-09-17 02:40:19 INFO  /home/ktian/anaconda3/envs/modisco_dev/lib/python2.7/site-packages/ipykernel_launcher.py -f /run/user/131/jupyter/kernel-b522265f-cf50-491e-a176-9a8aa5042fef.json\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "#import matplotlib as mpl\n",
    "#mpl.use('Agg')\n",
    "\n",
    "import numpy as np\n",
    "import modisco\n",
    "import theano\n",
    "import sys\n",
    "import argparse\n",
    "TFNET_ROOT = os.getenv('TFNET_ROOT', '/home/ktian/kundajelab/tfnet/')\n",
    "sys.path.append(TFNET_ROOT + \"/scripts\")\n",
    "    \n",
    "#modisco_dir = \"/home/ktian/kundajelab/tfnet/results/nandi/RELA/RELA_GM12878_refine_18_09_04/\"\n",
    "#modisco_dir = \"/Users/kat/kundajelab/tfnet/results/nandi/RELA/RELA_GM12878_18_08_25/\"\n",
    "#os.chdir(modisco_dir)\n",
    "tf = 'RELA'\n",
    "\n",
    "logging.basicConfig(\n",
    "        format='%(asctime)s %(levelname)-5s %(message)s',\n",
    "        level=logging.INFO,\n",
    "        datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "logging.info(\" \".join(sys.argv))\n",
    "\n",
    "\n",
    "logging.debug(\"Theano version:\" + str(theano.__version__))\n",
    "logging.debug(sys.version)\n",
    "\n",
    "\n",
    "# ### Functions for one-hot encoding sequences\n",
    "\n",
    "import gzip\n",
    "\n",
    "def one_hot_encode_along_channel_axis(sequence):\n",
    "    #theano dim ordering, uses row axis for one-hot\n",
    "    to_return = np.zeros((len(sequence),4), dtype=np.int8)\n",
    "    seq_to_one_hot_fill_in_array(zeros_array=to_return,\n",
    "                                 sequence=sequence, one_hot_axis=1)\n",
    "    return to_return\n",
    "\n",
    "def seq_to_one_hot_fill_in_array(zeros_array, sequence, one_hot_axis):\n",
    "    assert one_hot_axis==0 or one_hot_axis==1\n",
    "    if (one_hot_axis==0):\n",
    "        assert zeros_array.shape[1] == len(sequence)\n",
    "    elif (one_hot_axis==1):\n",
    "        assert zeros_array.shape[0] == len(sequence)\n",
    "    #will mutate zeros_array\n",
    "    for (i,char) in enumerate(sequence):\n",
    "        if (char==\"A\" or char==\"a\"):\n",
    "            char_idx = 0\n",
    "        elif (char==\"C\" or char==\"c\"):\n",
    "            char_idx = 1\n",
    "        elif (char==\"G\" or char==\"g\"):\n",
    "            char_idx = 2\n",
    "        elif (char==\"T\" or char==\"t\"):\n",
    "            char_idx = 3\n",
    "        elif (char==\"N\" or char==\"n\"):\n",
    "            continue #leave that pos as all 0's\n",
    "        else:\n",
    "            raise RuntimeError(\"Unsupported character: \"+str(char))\n",
    "        if (one_hot_axis==0):\n",
    "            zeros_array[char_idx,i] = 1\n",
    "        elif (one_hot_axis==1):\n",
    "            zeros_array[i,char_idx] = 1\n",
    "\n",
    "from merge_overlaps import MergeOverlaps\n",
    "from merge_overlaps import merge_overlaps\n",
    "\n",
    "'''\n",
    "def parse_args(args = None):\n",
    "    parser = argparse.ArgumentParser('run_tfmodisco.py',\n",
    "                                     description='run tfmodisco',\n",
    "                                     formatter_class=argparse.RawTextHelpFormatter)\n",
    "    parser.add_argument('--scores', type=str, help=\"prefix for the hypothetical score files\")\n",
    "    parser.add_argument('--fasta', type=str, help=\"fasta input\")\n",
    "    parser.add_argument('--tsv', type=str, help=\"tsv input\")\n",
    "    parser.add_argument('--start-task', type=int, default=0, help=\"start tast\")\n",
    "    parser.add_argument('--end-task', type=int, default=5, help=\"end task\")\n",
    "    parser.add_argument('--fdr', type=float, default=0.01, help=\"target FDR\")\n",
    "    args = parser.parse_args(args)\n",
    "    return args\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "score_prefix = args.scores\n",
    "input_name   = args.fasta\n",
    "input_tsv    = args.tsv\n",
    "start_task   = args.start_task\n",
    "end_task     = args.end_task\n",
    "target_fdr   = args.fdr\n",
    "'''\n",
    "\n",
    "\n",
    "#convert the motifs to log-odds space\n",
    "def log_odds_space(pwm, background,pseudocount):\n",
    "    new_pwm = []\n",
    "    for pos_values in np.transpose(pwm,(1,0)):\n",
    "        if sum(pos_values)==0:\n",
    "            new_pwm.append(pos_values)\n",
    "        else:\n",
    "            pos_values = pos_values+pseudocount/(1+pseudocount*4)\n",
    "            new_pwm.append(np.log(pos_values) - np.log(background))\n",
    "    return np.array(new_pwm).transpose(1,0)\n",
    "\n",
    "score_prefix = \"../scores/hyp_scores_task_\"\n",
    "input_name   = \"../interpret.fa\"\n",
    "input_tsv    = \"../interpret.tsv\"\n",
    "\n",
    "start_task = 0\n",
    "end_task   = 1\n",
    "\n",
    "logging.debug(\"method file prefix is %s, input seq file is %s, input tsv is %s, start_task is %d end_task is %d\",\n",
    "              score_prefix, input_name, input_tsv, start_task, end_task)\n",
    "\n",
    "#https://www.biostars.org/p/710/\n",
    "from itertools import groupby\n",
    "def fasta_iter(fasta_name):\n",
    "    \"\"\"\n",
    "        given a fasta file, yield tuples of (header, sequence)\n",
    "    \"\"\"\n",
    "    fh = open(fasta_name) # file handle\n",
    "    # ditch the boolean (x[0]) and just keep the header or sequence since they alternate\n",
    "    fa_iter = (x[1] for x in groupby(fh, lambda line: line[0] == \">\"))\n",
    "    for header in fa_iter:\n",
    "        header = header.next()[1:].strip() # drop the \">\" from the header\n",
    "        seq = \"\".join(s.strip() for s in fa_iter.next()) # join all sequence lines to one\n",
    "        yield header, seq\n",
    "\n",
    "fasta_sequences = []\n",
    "fasta = fasta_iter(input_name)\n",
    "\n",
    "for header, seq in fasta:\n",
    "    fasta_sequences.append(seq)\n",
    "logging.debug(\"lenth of sequences = %d\", len(fasta_sequences))\n",
    "\n",
    "#onehot_data = [one_hot_encode_along_channel_axis(seq) for seq in fasta_sequences]\n",
    "#logging.debug(\"shape of onehot\" + str(onehot_data[0].shape))\n",
    "\n",
    "# ## Prepare the data for input into TF-MoDISCo\n",
    "#\n",
    "# You need a numpy array of importance scores and hypothetical importance scores for every task.\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "task_to_scores = OrderedDict()\n",
    "task_to_hyp_scores = OrderedDict()\n",
    "\n",
    "# locations of deeplift scores\n",
    "scores_loc = []\n",
    "task_names = []\n",
    "for i in range(start_task , end_task):\n",
    "    loc_i = score_prefix + str(i) + \".npy\"\n",
    "    scores_loc.append(loc_i)\n",
    "    task_names.append(\"task\" + str(i))\n",
    "\n",
    "\n",
    "# scores & their one-hot encodings\n",
    "merged_seq_list        = []\n",
    "merged_onehot_list     = []\n",
    "merged_tsv_list        = []\n",
    "num_tasks = end_task - start_task\n",
    "for t in range(num_tasks):\n",
    "    merged_hyp_scores_list     = []\n",
    "    merged_contrib_scores_list = []\n",
    "    task = task_names[t]\n",
    "    hyp_scores_all = np.load(scores_loc[t])\n",
    "    merge_overlaps(input_tsv, hyp_scores_all, merged_hyp_scores_list, fasta_sequences,\n",
    "                   merged_seq_list = merged_seq_list if t==0 else None,\n",
    "                   merged_tsv_list = merged_tsv_list if t==0 else None                   )\n",
    "\n",
    "    for i in range(len(merged_hyp_scores_list)):\n",
    "        onehot_seq = one_hot_encode_along_channel_axis(merged_seq_list[i])\n",
    "        contrib_scores = merged_hyp_scores_list[i] * onehot_seq\n",
    "        merged_contrib_scores_list.append(contrib_scores)\n",
    "        if t == 0:\n",
    "            merged_onehot_list.append(onehot_seq)\n",
    "\n",
    "    task_to_hyp_scores[task] = merged_hyp_scores_list\n",
    "    task_to_scores[task]     = merged_contrib_scores_list\n",
    "\n",
    "    if t == 0:\n",
    "        logging.debug(\"shape of hyp_score \" + str(task_to_hyp_scores[task][0].shape))\n",
    "        logging.debug(\"shape of score \" + str(task_to_scores[task][0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnp.savez(\"merged_scores.npz\", *merged_hyp_scores_list)\\nwith open(\"merged.tsv\", \\'w\\') as fh:\\n    for tsv in merged_tsv_list:\\n        fields = [str(f) for f in tsv]\\n        fh.write(\"\\t\".join(fields) + \"\\n\")\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the scores and tsv\n",
    "'''\n",
    "np.savez(\"merged_scores.npz\", *merged_hyp_scores_list)\n",
    "with open(\"merged.tsv\", 'w') as fh:\n",
    "    for tsv in merged_tsv_list:\n",
    "        fields = [str(f) for f in tsv]\n",
    "        fh.write(\"\\t\".join(fields) + \"\\n\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the saved hdf5 file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the results object from the saved file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    reload  # Python 2.7\n",
    "except NameError:\n",
    "    try:\n",
    "        from importlib import reload  # Python 3.4+\n",
    "    except ImportError:\n",
    "        from imp import reload  # Python 3.0 - 3.3\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import modisco.util\n",
    "import modisco.core\n",
    "reload(modisco.core)\n",
    "import modisco.metaclusterers\n",
    "reload(modisco.metaclusterers)\n",
    "import modisco.coordproducers\n",
    "reload(modisco.coordproducers)\n",
    "import modisco.tfmodisco_workflow.seqlets_to_patterns\n",
    "import modisco.tfmodisco_workflow\n",
    "reload(modisco.tfmodisco_workflow.seqlets_to_patterns)\n",
    "reload(modisco.tfmodisco_workflow)\n",
    "from modisco.tfmodisco_workflow import workflow\n",
    "reload(workflow)\n",
    "\n",
    "\n",
    "# read snp.txt format: chr:pos\n",
    "\n",
    "# load the motifs from the results\n",
    "track_set = modisco.tfmodisco_workflow.workflow.prep_track_set(\n",
    "                task_names=task_names,\n",
    "                contrib_scores=task_to_scores,\n",
    "                hypothetical_contribs=task_to_hyp_scores,\n",
    "                one_hot=merged_onehot_list)\n",
    "\n",
    "grp = h5py.File(\"results.hdf5\",\"r\")\n",
    "loaded_tfmodisco_results =\\\n",
    "    workflow.TfModiscoResults.from_hdf5(grp, track_set=track_set)\n",
    "grp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_res = loaded_tfmodisco_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['metacluster_0,pattern_0', 'metacluster_0,pattern_1', 'metacluster_0,pattern_2']\n"
     ]
    }
   ],
   "source": [
    "from modisco import affinitymat\n",
    "reload(affinitymat.core)\n",
    "reload(affinitymat)\n",
    "from modisco import hit_scoring\n",
    "reload(hit_scoring.fast_hit_scoring)\n",
    "reload(hit_scoring)\n",
    "from collections import OrderedDict\n",
    "\n",
    "task_names = loaded_tfmodisco_results.task_names\n",
    "\n",
    "seqlet_size_to_score_with = 25\n",
    "\n",
    "metacluster_idx_to_scorer = OrderedDict()\n",
    "\n",
    "all_pattern_scorers = []\n",
    "all_pattern_names = []\n",
    "\n",
    "for metacluster_name in\\\n",
    "    sorted(loaded_tfmodisco_results\n",
    "           .metacluster_idx_to_submetacluster_results.keys()):\n",
    "    submetacluster_results =(\n",
    "        loaded_tfmodisco_results\n",
    "            .metacluster_idx_to_submetacluster_results[metacluster_name])\n",
    "    activity_pattern = submetacluster_results.activity_pattern\n",
    "    relevant_task_names = [task_name for (task_name,x) in\n",
    "                           zip(task_names, activity_pattern) if np.abs(x) != 0]\n",
    "    \n",
    "    patterns_in_submetacluster =\\\n",
    "        submetacluster_results.seqlets_to_patterns_result.patterns\n",
    " \n",
    "\n",
    "    for pattern_idx, pattern in\\\n",
    "        enumerate(submetacluster_results.\n",
    "                   seqlets_to_patterns_result.patterns):\n",
    "        metacluster_idx = int(metacluster_name.split(\"_\")[1])\n",
    "        all_pattern_names.append(\"metacluster_\"+str(metacluster_idx)\n",
    "                             +\",pattern_\"+str(pattern_idx))\n",
    "\n",
    "\n",
    "print(all_pattern_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8917\n",
      "[[1516658208L, 'chr6', 16658208, 4428], [1516685601L, 'chr6', 16685601, 767], [1516685658L, 'chr6', 16685658, 4365], [1516691743L, 'chr6', 16691743, 656], [1516695175L, 'chr6', 16695175, 7054]]\n"
     ]
    }
   ],
   "source": [
    "all_patterns = [x for y in\n",
    "                  sorted(loaded_tfmodisco_results\n",
    "                  .metacluster_idx_to_submetacluster_results.keys())\n",
    "                  for x in\n",
    "                   loaded_tfmodisco_results\n",
    "                   .metacluster_idx_to_submetacluster_results[y]\n",
    "                   .seqlets_to_patterns_result.patterns]\n",
    "seqlets_to_score = []\n",
    "seqlets_to_score_true_labels = []\n",
    "for i,pattern in enumerate(all_patterns):\n",
    "    seqlets_to_score.extend(pattern.seqlets)\n",
    "    seqlets_to_score_true_labels.extend(\n",
    "        [i for x in pattern.seqlets])\n",
    "\n",
    "MAX_LOC = 250000000L\n",
    "def chrom_to_idx(chrom, loc):\n",
    "    chrid = chrom[3:]\n",
    "    if chrid == 'x' or chrid == 'X':\n",
    "        chrnm = 23\n",
    "    elif chrid == 'y' or chrid == 'Y':\n",
    "        chrnm = 24\n",
    "    else:\n",
    "        chrnm = int(chrid)\n",
    "    return long(chrnm * MAX_LOC + loc)\n",
    "\n",
    "def idx_to_chrom(idx):\n",
    "    loc = idx % MAX_LOC\n",
    "    chrid = int(idx / MAX_LOC)\n",
    "    if chrid == 23:\n",
    "        chrom = 'chrX'\n",
    "    elif chrid == 24:\n",
    "        chrom = 'chrY'\n",
    "    else:\n",
    "        chrom = 'chr' + str(chrid)\n",
    "    return chrom, loc\n",
    "        \n",
    "    \n",
    "def calc_seq_loc(seq):\n",
    "    st = seq.coor.start\n",
    "    en = seq.coor.end\n",
    "    local = int((st + en)/2) # fix later using center of gravity\n",
    "\n",
    "    tsv = merged_tsv_list[seq.coor.example_idx]\n",
    "    location = int(tsv[1]) + local\n",
    "    if location > MAX_LOC:\n",
    "        print(\"location=%d, tsv_start=%d, ex=%d, st=%d, en=%d\" %(location, int(tsv[1]), seq.coor.example_idx, seq.coor.start, seq.coor.end))\n",
    "        print(tsv)\n",
    "    idx = chrom_to_idx(tsv[0], location)\n",
    "\n",
    "    return idx, tsv[0], location\n",
    "    \n",
    "seqlets_locs = [list(calc_seq_loc(seq)) + [i] for i, seq in enumerate(seqlets_to_score)]\n",
    "\n",
    "\n",
    "seqlets_locs_sorted = sorted(seqlets_locs, key=lambda x: long(x[0]))\n",
    "idx_array = [x[0] for x in seqlets_locs_sorted]\n",
    "\n",
    "print(len(seqlets_to_score_true_labels))\n",
    "#print(seqlets_to_score_true_labels)\n",
    "#print(seqlets_locs[:5])\n",
    "print(seqlets_locs_sorted[2595:2600])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 804, 1476, 1878, 2450, 3195, 3665, 4085, 4475, 4951, 5432, 5960, 6168, 6508, 6871, 7204, 7617, 7816, 8112, 8351, 8478, 8669, 8917, 8917, 0]\n",
      "250000000\n"
     ]
    }
   ],
   "source": [
    "from bisect import bisect_left\n",
    "max_chrid = 25\n",
    "bounds  = [0] * (max_chrid+1)\n",
    "for chrid in range(1, max_chrid+1):\n",
    "    lo_val = chrid * MAX_LOC\n",
    "    bounds[chrid-1] = bisect_left(idx_array, lo_val)\n",
    "    #print(chrid-1, lo_val, bounds[chrid-1])\n",
    "\n",
    "print(bounds)\n",
    "print(MAX_LOC)\n",
    "\n",
    "def find_nearest(my_list, my_idx):\n",
    "    \"\"\"\n",
    "    Assumes my_list is sorted. Returns closest value to my_idx.\n",
    "    If two numbers are equally close, return the smallest number.\n",
    "    If lo\n",
    "    \"\"\"\n",
    "\n",
    "    chrid = long(my_idx / MAX_LOC)\n",
    "    lo = bounds[chrid-1]\n",
    "    hi = bounds[chrid]\n",
    "    if lo == hi:\n",
    "        return -1, -1 # this chrom is empty\n",
    "    \n",
    "    # lo != hi, so the chrom is not empty\n",
    "    pos = bisect_left(my_list, my_idx, lo=lo, hi=hi)\n",
    "\n",
    "    if pos == lo:\n",
    "        return lo, my_list[lo]\n",
    "    if pos == hi:\n",
    "        return hi-1, my_list[hi-1] # hi belongs to next chrom\n",
    "    before = my_list[pos - 1]\n",
    "    after = my_list[pos]\n",
    "    #print(lo, hi, pos, before, after)\n",
    "    if after - my_idx < my_idx - before:\n",
    "       return pos, after\n",
    "    else:\n",
    "       return pos-1, before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1L, 114.49091982717546], [1L, 74.94768409975464], [703346L, 35.35085960322312], [153917L, 33.16095717805289], [466869L, 32.37803364766699]]\n",
      "1410823\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "#snp_dir = \"/Users/kat/kundajelab/tmp/bQTL/bQTL_all_SNPs/\"\n",
    "snp_dir = \"/home/ktian/kundajelab/tfnet/results/nandi/bQTL/analysis/bQTL_all_SNPs/\"\n",
    "snp_list = []\n",
    "with open(snp_dir + tf + \".txt\") as in_fh:\n",
    "    header = next(in_fh)\n",
    "    line_num = 0\n",
    "    for line in in_fh:\n",
    "        fields = line.split('\\t')\n",
    "        snp_chrom = fields[0]\n",
    "        snp_pos   = int(fields[1])\n",
    "        pval  = float(fields[9])\n",
    "        idx   = chrom_to_idx(snp_chrom, snp_pos)\n",
    "        motif_off, motif_idx = find_nearest(idx_array, idx)\n",
    "        if motif_off >= 0:\n",
    "            #snp_list.append([abs(idx-motif_idx), -math.log(pval), pval, idx, snp_chrom, snp_pos, line_num, motif_idx, motif_off])\n",
    "            snp_list.append([abs(idx-motif_idx), -math.log(pval, 10)])\n",
    "        line_num += 1\n",
    "print(snp_list[:5])     \n",
    "print(len(snp_list))\n",
    "with open(tf + \"_modisco_snp_dist_pval_full.tsv\", \"w\") as fh:\n",
    "    for row in snp_list:\n",
    "        fh.write(str(row[0]) +\"\\t\"+ str(row[1]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlogging.basicConfig(\\n        format=\\'%(asctime)s %(levelname)-5s %(message)s\\',\\n        level=logging.INFO,\\n        datefmt=\\'%Y-%m-%d %H:%M:%S\\')\\n\\n%matplotlib inline\\n\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport matplotlib\\nfrom scipy.stats import gaussian_kde\\n\\n#fig=plt.figure(figsize=(10, 8), dpi= 100)\\nsnp_dist = [item[0] for item in snp_list if item[1] > 0 and item[0] <= 1000]\\nsnp_pval = [item[1] for item in snp_list if item[1] > 0 and item[0] <= 1000]\\n\\nx=snp_dist\\ny=snp_pval\\nxy = np.vstack([x,y])\\nz = gaussian_kde(xy)(xy)\\n\\nprint(\"Of top 100k \"+tf+\" SNPs with highest p-val, \", len(snp_dist), \" SNPs have distance to nearest motif center < 1000\")\\n\\nfig = plt.figure()\\nax = fig.add_axes([1,1,1,1])\\nplt.scatter(snp_dist, snp_pval, 1, c=z, alpha=1, marker=\\'o\\', label=\".\")\\nplt.xlabel(\"SNP distance to \" + tf + \" motif centers, \" + str(len(snp_dist)) + \" SNPs\")\\nplt.ylabel(\"SNP -log10(pval)\")\\nplt.colorbar(label=\\'density (low to high)\\')\\n\\n#plt.legend(loc=2)\\nplt.show()    \\nfig.savefig(tf+\"_snp_1k_big.png\", bbox_inches=\\'tight\\')\\n# https://stackoverflow.com/questions/20105364/how-can-i-make-a-scatter-plot-colored-by-density-in-matplotlib\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "logging.basicConfig(\n",
    "        format='%(asctime)s %(levelname)-5s %(message)s',\n",
    "        level=logging.INFO,\n",
    "        datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "#fig=plt.figure(figsize=(10, 8), dpi= 100)\n",
    "snp_dist = [item[0] for item in snp_list if item[1] > 0 and item[0] <= 1000]\n",
    "snp_pval = [item[1] for item in snp_list if item[1] > 0 and item[0] <= 1000]\n",
    "\n",
    "x=snp_dist\n",
    "y=snp_pval\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "print(\"Of top 100k \"+tf+\" SNPs with highest p-val, \", len(snp_dist), \" SNPs have distance to nearest motif center < 1000\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([1,1,1,1])\n",
    "plt.scatter(snp_dist, snp_pval, 1, c=z, alpha=1, marker='o', label=\".\")\n",
    "plt.xlabel(\"SNP distance to \" + tf + \" motif centers, \" + str(len(snp_dist)) + \" SNPs\")\n",
    "plt.ylabel(\"SNP -log10(pval)\")\n",
    "plt.colorbar(label='density (low to high)')\n",
    "\n",
    "#plt.legend(loc=2)\n",
    "plt.show()    \n",
    "fig.savefig(tf+\"_snp_1k_big.png\", bbox_inches='tight')\n",
    "# https://stackoverflow.com/questions/20105364/how-can-i-make-a-scatter-plot-colored-by-density-in-matplotlib\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n%matplotlib inline\\n\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport matplotlib\\nfrom scipy.stats import gaussian_kde\\n\\nfor item in snp_list:\\n    if item[0] == 0:\\n        item[0] = 0.1\\n#fig=plt.figure(figsize=(10, 8), dpi= 100)\\nsnp_dist = [item[0] for item in snp_list]\\nsnp_pval = [item[1] for item in snp_list]\\n\\nx=snp_dist\\ny=snp_pval\\nxy = np.vstack([x,y])\\nz = gaussian_kde(xy)(xy)\\n\\nprint(\"Of top 100k \"+tf+\" SNPs with highest p-val, \", len(snp_dist), \" SNPs have motif in the same Chromosome\")\\nfig = plt.figure()\\nax = fig.add_axes([1,1,1,1])\\nplt.scatter(snp_dist, snp_pval, 1, c=z, alpha=1, marker=\\'o\\', label=\".\")\\nplt.xscale(\\'log\\')\\n#plt.yscale(\\'log\\')\\nplt.xlabel(\"SNP distance to \"+ tf +\" motif centers, \" + str(len(snp_dist)) + \" SNPs\")\\nplt.ylabel(\"SNP -log10(pval)\")\\nplt.colorbar(label=\\'density (low to high)\\')\\n\\n#plt.legend(loc=2)\\nplt.show()  \\nfig.savefig(tf+\"_snp_log_big.png\", bbox_inches=\\'tight\\')\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "for item in snp_list:\n",
    "    if item[0] == 0:\n",
    "        item[0] = 0.1\n",
    "#fig=plt.figure(figsize=(10, 8), dpi= 100)\n",
    "snp_dist = [item[0] for item in snp_list]\n",
    "snp_pval = [item[1] for item in snp_list]\n",
    "\n",
    "x=snp_dist\n",
    "y=snp_pval\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "print(\"Of top 100k \"+tf+\" SNPs with highest p-val, \", len(snp_dist), \" SNPs have motif in the same Chromosome\")\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([1,1,1,1])\n",
    "plt.scatter(snp_dist, snp_pval, 1, c=z, alpha=1, marker='o', label=\".\")\n",
    "plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "plt.xlabel(\"SNP distance to \"+ tf +\" motif centers, \" + str(len(snp_dist)) + \" SNPs\")\n",
    "plt.ylabel(\"SNP -log10(pval)\")\n",
    "plt.colorbar(label='density (low to high)')\n",
    "\n",
    "#plt.legend(loc=2)\n",
    "plt.show()  \n",
    "fig.savefig(tf+\"_snp_log_big.png\", bbox_inches='tight')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modisco_dev",
   "language": "python",
   "name": "modisco_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
