[
{
    "message": "example model and training config",
    "other_data_loaders":{
        "train": {
            "class": "hdf5_data_loader.MultimodalBatchDataLoader",
            #"class": "hdf5_data_loader.MultimodalAtOnceDataLoader",
            "kwargs": {
                "batch_size": 200,
                "path_to_hdf5": "train_data.hdf5",
                "num_to_load_for_eval": 100000, #if my training data is large
                #and I only want to load a subset when I'm calculating the
                #performance stats on the training data, specify this number,
                #and only that many datapoints of the training data will be used
                #for performance stat calculation
                "bundle_x_and_y_in_generator": False,
                "strip_enclosing_dictionary": True
            }
        }
    },
    "model_creator":{
        "class": "flexible_keras.KerasModelFromSavedFile",
        "kwargs": {
                "weight_file": "../ZNF143_20_pre/model_files/record_1_model_pretrain_Weights.h5",
                "json_file": "../ZNF143_20_pre/model_files/record_1_model_pretrain_Json.json",
                "optimizer_config": {
                    "class": "keras.optimizers.Adam",
                    "kwargs": {
                        "lr": .0002
                    }
                },
                "loss": {
                    "modules_to_load": ["keras_genomics"],
                    "func": "keras_genomics.losses.ambig_binary_crossentropy"
                }
        } 
    },
   "model_trainer":{
        "class": "keras_model_trainer.KerasFitGeneratorModelTrainer",
        "kwargs": {
            "seed": 1234,
            "samples_per_epoch": 60,
            "stopping_criterion_config": {
                "class": "EarlyStopping" ,
                "kwargs": {
                   "max_epochs": 1000, 
                   "epochs_to_wait": 20
                } 
            },
            #"class_weight": {"0":1, "1":25}
        }
    },
}
]
