[
{
    "message": "model & config for SPI1, 1 task, refine, ver 18_07_31",
    "other_data_loaders":{
        "train": {
            "class": "hdf5_data_loader.MultimodalBatchDataLoader",
            "kwargs": {
                "batch_size": 200,
                "path_to_hdf5": "train_data.hdf5",
                "num_to_load_for_eval": 50000, #if my training data is large
                #and I only want to load a subset when I'm calculating the
                #performance stats on the training data, specify this number,
                #and only that many datapoints of the training data will be used
                #for performance stat calculation
                "bundle_x_and_y_in_generator": False,
                "strip_enclosing_dictionary": True,
                "rc_augment": True
            }
        }
    },
    "model_creator":{
        "class": "flexible_keras.FlexibleKerasSequential",
        "kwargs": {
            "pretrained_model_config": {
                "weight_file": "pretrain/model_files/record_1_Weights.h5",
                "json_file":   "pretrain/model_files/record_1_Json.json",
                "last_layer_to_take": -2
            },
            "layers_config": [
                { "class": "keras.layers.core.Dense", "kwargs": {"output_dim": 1, "name": "dense_2"} },
                { "class": "keras.layers.core.Activation", "kwargs": {"activation": "sigmoid", "name": "activation_5"} }
            ],
            "optimizer_config": {
                "class": "keras.optimizers.Adam",
                "kwargs": {"lr": 0.001}
            },
            "loss": {
                "modules_to_load": ["keras_genomics"],
                "func": "keras_genomics.losses.ambig_binary_crossentropy"
            }
        }
    },
    "model_trainer":{
        "class": "keras_model_trainer.KerasFitGeneratorModelTrainer",
        "kwargs": {
            "seed": 1234,
            "samples_per_epoch": 60,
            "stopping_criterion_config": {
                "class": "EarlyStopping" ,
                "kwargs": {
                   "max_epochs": 1000,
                   "epochs_to_wait": 20
                }
            },
            #"class_weight": {"0":1, "1":10}
        }
    },
}
]

