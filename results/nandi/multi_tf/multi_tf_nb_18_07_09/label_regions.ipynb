{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The label_regions script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "'''\n",
    "This script generates labels for given regions based the peaks files\n",
    "downloaded from ENCODE project. \n",
    "\n",
    "Following is one example of how the script may be called to prepare \n",
    "the TF binding data from three experiments ENCSR000AKB, ENCSR000BJE, \n",
    "and ENCSR000DZL on cell line GM12878 for the data processing pipeline \n",
    "that involves deep learning with momma_dragonn, deepLIFT analysis, \n",
    "and MoDisCO motif analysis.\n",
    "\n",
    "/home/ktian/kundajelab/tfnet/scripts/label_regions \\\n",
    "--positives \\\n",
    "/home/ktian/kundajelab/tfnet/ENCODE_data/GM12878-CTCF-human-ENCSR000AKB-optimal_idr.narrowPeak.gz,\\\n",
    "/home/ktian/kundajelab/tfnet/ENCODE_data/GM12878-SIX5-human-ENCSR000BJE-optimal_idr.narrowPeak.gz,\\\n",
    "/home/ktian/kundajelab/tfnet/ENCODE_data/GM12878-ZNF143-human-ENCSR000DZL-optimal_idr.narrowPeak.gz \\\n",
    " \\\n",
    "--ambiguous ./_tmp_tuJQRK/_tmp_GM12878-CTCF-human-ENCSR000AKB-merged.narrowPeak.gz,\\\n",
    "./_tmp_tuJQRK/_tmp_GM12878-SIX5-human-ENCSR000BJE-merged.narrowPeak.gz,\\\n",
    "./_tmp_tuJQRK/_tmp_GM12878-ZNF143-human-ENCSR000DZL-merged.narrowPeak.gz\\\n",
    " \\\n",
    "--background /home/ktian/kundajelab/tfnet/genome/hg19.tsv \\\n",
    "--prefix label  --stride 20 \\\n",
    "\n",
    "Arguments:\n",
    "----------\n",
    "Most of the syntax is borrowed from tfdragonn label-regions to\n",
    "maintain compatibility. The difference is that this script \n",
    "uses native bedtools instead of PyBedtools \n",
    "\n",
    "--positives : gives a list of positive narrow peak files separated \n",
    "    by comma(','). Each of the positive peak file comes from\n",
    "    an experiment and will define a task in the subsequent training \n",
    "    and analysis. In this example, three positive peak files were \n",
    "    given.\n",
    "\n",
    "--ambiguous : gives ambiguous peaks files, separatedby comma(','), \n",
    "    one for each experiment. The positive and ambiguous peak files \n",
    "    from the same experiment must appear in the same order. \n",
    "    If any experiment has more than one ambiguous peak files, \n",
    "    they must be merged to produce a single ambiguous peak file. If any\n",
    "    experiment has no ambiguous peak file, use '/dev/null' in its place.\n",
    "    In this example, three merged ambiguous peak files were given.\n",
    "\n",
    "--background : specifys the background region. In this example, \n",
    "    we specified hg19.tsv which gives the whole genome as the \n",
    "    background. Following is the beginning of hg19.tsv file.\n",
    "    \n",
    "    $ head hg19.tsv \n",
    "    chr1\t1\t249250621\n",
    "    chr10\t1\t135534747\n",
    "    chr11\t1\t135006516\n",
    "    chr12\t1\t133851895\n",
    "    chr13\t1\t115169878\n",
    "    ...\n",
    "\n",
    "--prefix : specifies the prefix of the output label file. In this example,\n",
    "    the prefix 'label' is given, so the overall file name will be \n",
    "    label.intervals_file.tsv.gz\n",
    "    \n",
    "--stride : the stride used when making sliding windows, 20 is given\n",
    "    in this example.\n",
    "    \n",
    "There are other possible arguments defined below. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def parse_args(args = None):\n",
    "    '''\n",
    "    argument parsing borrowed from tf-dragonn labelregions.\n",
    "    '''\n",
    "    parser = argparse.ArgumentParser('label_regions',\n",
    "                                     description='Generate fixed length regions and their'\n",
    "                                     ' labels for each dataset.',\n",
    "                                     formatter_class=argparse.RawTextHelpFormatter)\n",
    "    #parser.add_argument('--raw-intervals-config-file', type=os.path.abspath, default=None,\n",
    "    #                    help='Includes task names and a map from dataset id -> raw interval file')\n",
    "    parser.add_argument('--positives', type=str, default=None, help='positive bed files for each task, separated by commas.')\n",
    "    parser.add_argument('--ambiguous', type=str, default=None, help='ambiguous bed files for each task, separated by commas.')\n",
    "    parser.add_argument('--background', type=str, default=None, help='background bed file.')\n",
    "    parser.add_argument('--prefix', type=str, required=True, help='prefix of output files')\n",
    "    parser.add_argument('--n-jobs', type=int, default=1,\n",
    "                        help='num of processes.\\nDefault: 1.')\n",
    "    parser.add_argument('--bin-size', type=int, default=200,\n",
    "                        help='size of bins for labeling.\\nDefault: 200.')\n",
    "    parser.add_argument('--flank-size', type=int, default=400,\n",
    "                        help='size of flanks around labeled bins.\\nDefault: 400.')\n",
    "    parser.add_argument('--stride', type=int, default=50,\n",
    "                        help='spacing between consecutive bins.\\nDefault: 50.')\n",
    "    parser.add_argument('--genome', type=str, default='hg19',\n",
    "                        help='Genome name.\\nDefault: hg19.'\n",
    "                        '\\nOptions: hg18, hg38, mm9, mm10, dm3, dm6.')\n",
    "    #parser.add_argument('--logdir', type=os.path.abspath,\n",
    "    #                    help='Logging directory', default=None, required=False)\n",
    "    args = parser.parse_args(args)\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The directory layout is defined here, as relative path are used sometimes.\n",
    "\n",
    "$TFNET_ROOT is set to the root of TFNET dir\n",
    " /-- scripts       such as label_region, prepare_data.py, run_deeplift.py, run_modisco.py, run_pipeline.py etc\n",
    " /-- genome        hg19.fa hg19.chrom.sizes hg19.tsv\n",
    " /-- ENCODE_data   peak files downloaded from ENCODE project\n",
    " /-- results       results\n",
    "      |\n",
    "      /-- nandi----/-- multi_tf --/-- multi_tf_nb_18_07_09/ working dirs down here\n",
    "      |            /-- ZNF143\n",
    "      |\n",
    "      /-- nautilus-/-- CTCF\n",
    "      |            /-- ZFX\n",
    "      |\n",
    "      /-- templates/-- config\n",
    "'''\n",
    "import os\n",
    "from os.path import basename\n",
    "\n",
    "ROOT_DIR   = os.getenv('TFNET_ROOT', \"../../\") \n",
    "scriptDir  = ROOT_DIR + \"/scripts/\"\n",
    "dataDir    = ROOT_DIR + \"/ENCODE_data/\"\n",
    "genomeDir  = ROOT_DIR + \"/genome/\"\n",
    "resultsDir = \"./\"\n",
    "logDir     = resultsDir + \"log/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "A typical debug message looks like the following:\n",
    "2018-07-09 01:09:14 DEBUG processing DONE\n",
    "'''\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "        format='%(asctime)s %(levelname)-5s %(message)s',\n",
    "        level=logging.DEBUG,\n",
    "        datefmt='%Y-%m-%d %H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "load the sizes of each chromosome so that we can ignore the first and last 5000 bp\n",
    "'''\n",
    "chrom_sizes = {}\n",
    "def load_chrom_sizes(chrom_sizes_fn):\n",
    "    global chrom_sizes\n",
    "    chrom_sizes = {}\n",
    "    with open(chrom_sizes_fn) as genome_fh:\n",
    "        for line in genome_fh:\n",
    "            chrom, size = line.split()\n",
    "            chrom_sizes[chrom.strip()] = int(size)\n",
    "\n",
    "# ignore the first and last 5000 bp of each chromosome \n",
    "min_dist_from_edge = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_windows(in_name, out_name, bin_size = 200, stride = 50, expand = True):\n",
    "    '''\n",
    "        takes in regions and expands region lengths to be a multiple of stride (default 50)\n",
    "        outputs a list of regions, result of sliding window of length bin_size (default 200)\n",
    "    '''\n",
    "    with open(in_name,'r') as tsvin, open(out_name, 'w') as tsvout:\n",
    "        # for row in tsvin:\n",
    "        for cnt, line in enumerate(tsvin):\n",
    "            row = line.split()\n",
    "            chrom = row[0]\n",
    "            start = int(row[1])\n",
    "            end   = int(row[2])\n",
    "\n",
    "            if chrom[3] == 'M' or chrom[3] == 'm':\n",
    "                continue\n",
    "            if len(chrom) > 5:\n",
    "                continue\n",
    "\n",
    "            peak_length = end - start\n",
    "            if expand :\n",
    "                # total_length = stride * ceiling = smallest multiple of stride greater than peak_length\n",
    "                total_length = stride * int((peak_length - bin_size + stride - 1)/stride) + bin_size\n",
    "            else : \n",
    "                total_length = peak_length # no expand\n",
    "\n",
    "            # extend_left = int((total_length - peak_length)/2) # extend on both sides\n",
    "            extend_left = 0 # extand only on the right, this is tf-dragonn's style\n",
    "            extend_right = total_length - peak_length - extend_left\n",
    "\n",
    "            left  = start - extend_left\n",
    "            right = end + extend_right\n",
    "\n",
    "            # write out the new \"unified\" intervals\n",
    "            right_max = chrom_sizes[chrom] - min_dist_from_edge\n",
    "            for le in range(max(left, min_dist_from_edge), \n",
    "                            min(right, right_max) - bin_size + 1, stride):\n",
    "                tsvout.write(chrom + \"\\t\" + str(le) + \"\\t\" + str(le + bin_size) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import contextlib\n",
    "@contextlib.contextmanager\n",
    "def dummy_context_mgr():\n",
    "    yield None\n",
    "\n",
    "def label_regions_fast(region, positive, ambiguous, labels):\n",
    "    '''\n",
    "        label regions for one task\n",
    "        O(n) to go through intervals in region file and label them\n",
    "        assuming regions, positives, ambiguous files are all sorted\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        region:     input file with list of intervals to be labeled\n",
    "        positive:   input file with list of positive intervals (subset of region)\n",
    "        ambiguous:  input file with list of ambiguous intervals (subset of region)\n",
    "        labels:     output file with one column of labels\n",
    "    '''\n",
    "    \n",
    "    # Open the file with read only permit\n",
    "    with open(region,'r') as reg, open(positive, 'r') as pos, open (labels, 'w') as lab:\n",
    "        \n",
    "        # conditional with block\n",
    "        with open(ambiguous, 'r') if ambiguous != None else dummy_context_mgr() as amb:\n",
    "\n",
    "            # read in p_line, r_line, and a_line from files\n",
    "            p_line = pos.readline()\n",
    "            r_line = reg.readline()\n",
    "            if ambiguous != None:\n",
    "                a_line = amb.readline()\n",
    "                read_a = True\n",
    "            else:\n",
    "                a_line = None\n",
    "                read_a = False\n",
    "\n",
    "            # iterate through regions & determine labels\n",
    "            while r_line:\n",
    "                read_p = False # if p matched r and we should move to next positive interval\n",
    "                read_a = False # if a matched r ...\n",
    "                if r_line == p_line: # positive\n",
    "                    out = 1\n",
    "                    read_p = True\n",
    "                    if r_line == a_line:\n",
    "                        read_a = True\n",
    "                elif r_line == a_line: # ambiguous\n",
    "                    out = -1\n",
    "                    read_a = True\n",
    "                else: # negative\n",
    "                    out = 0\n",
    "\n",
    "                lab.write(str(out) + \"\\n\")\n",
    "\n",
    "                r_line = reg.readline()\n",
    "                if read_p:\n",
    "                    p_line = pos.readline()\n",
    "                if read_a:\n",
    "                    a_line = amb.readline()\n",
    "# can be simplified if we use intersect -c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_peaks(positives, ambiguous):\n",
    "    '''\n",
    "    # unzip all original positive  input interval files to tmpDir\n",
    "    # unzip all original ambiguous input interval files to tmpDir\n",
    "    '''\n",
    "\n",
    "    ### positives\n",
    "    pos_unzips = []\n",
    "    for p_orig in positives:\n",
    "        if p_orig[-3:] == \".gz\":\n",
    "            # basename extracts the last part of the path, the filename\n",
    "            p_unzip = tmpDir + basename(p_orig[:-3]) # remove \".gz\" from filename\n",
    "\n",
    "            # unzip and sort p_orig to p_unzip\n",
    "            os.system(\"pigz -d -c \" + p_orig + \" | bedtools sort > \" + p_unzip) \n",
    "        else:\n",
    "            p_unzip = tmpDir + basename(p_orig)\n",
    "            # copy and sort p_orig to p_unzip\n",
    "            os.system(\"cat \"       + p_orig + \" | bedtools sort > \" + p_unzip) \n",
    "        pos_unzips.append(p_unzip)\n",
    "\n",
    "    ### ambigous\n",
    "    amb_unzips = None\n",
    "    if ambiguous != None:\n",
    "        assert(len(positives) == len(ambiguous)) # ensure same number of tasks\n",
    "        \n",
    "        amb_unzips = []\n",
    "        for a_orig in ambiguous:\n",
    "            if a_orig == None:\n",
    "                a_unzip = \"\"\n",
    "            else:\n",
    "                if a_orig[-3:] == \".gz\":\n",
    "                    a_unzip = tmpDir + basename(a_orig[:-3]) # remove \".gz\"\n",
    "                    os.system(\"pigz -d -c \" + a_orig + \" | bedtools sort > \" + a_unzip)\n",
    "                else:\n",
    "                    a_unzip = tmpDir + basename(a_orig)\n",
    "                    os.system(\"cat \"       + a_orig + \" | bedtools sort > \" + a_unzip)\n",
    "            amb_unzips.append(a_unzip)\n",
    "\n",
    "    return pos_unzips, amb_unzips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_intersects(pos_unzips, amb_unzips, tmp_regions):\n",
    "    # generate intersects with positives\n",
    "    pos_intersects = []\n",
    "    for p in pos_unzips:\n",
    "        p_intersect = tmpDir + \"_tmp_pint_\" + basename(p)\n",
    "        os.system(\"bedtools intersect -a \" + tmp_regions + \" -b \" + p + \\\n",
    "            \" -sorted -wa -f 0.5 -F 0.5 -e -u > \" + p_intersect) # add -c later\n",
    "        #os.system(\"bedtools intersect -a \" + tmp_core_regions + \" -b \" + p + \\\n",
    "        #    \" -sorted -wa -f 0.5 -F 0.5 -e -c | cut -f 4 > \" + p_intersect)\n",
    "        pos_intersects.append(p_intersect)\n",
    "\n",
    "    # generate intersects with ambiguous\n",
    "    amb_intersects = []\n",
    "    for a in amb_unzips:\n",
    "        a_intersect = tmpDir + \"_tmp_aint_\" + basename(a)\n",
    "        os.system(\"bedtools intersect -a \" + tmp_regions + \" -b \" + a + \\\n",
    "            \" -sorted -wa -f 0.5 -F 0.5 -e -u > \" + a_intersect) # add -c later\n",
    "        #os.system(\"bedtools intersect -a \" + tmp_core_regions + \" -b \" + a + \\\n",
    "        #    \" -sorted -wa -f 0.5 -F 0.5 -e -c | cut -f 4 > \" + a_intersect)\n",
    "        amb_intersects.append(a_intersect)\n",
    "\n",
    "    return pos_intersects, amb_intersects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_background_intervals(regions, tmp_core_regions, chrom_sizes_fn, \n",
    "                                bin_size=200, flank_size=400):\n",
    "    if regions == None:\n",
    "        # if no background regions were specified, use the union of positives as regions\n",
    "        tmp_regions = tmp_core_regions\n",
    "    else:    # sort and merge the background regions\n",
    "        tmp_regions = tmpDir + \"_tmp_regions.tsv\"\n",
    "        cmd = \"cat \" + regions + \" | cut -f 1-3 | bedtools sort | bedtools merge  > \" + tmp_regions\n",
    "        os.system(cmd)\n",
    "\n",
    "        tmp_expanded_bkg_regions = tmpDir + \"_tmp_expanded_bkg_regions.tsv\"\n",
    "        expanded_window_size = bin_size + 2 * flank_size\n",
    "\n",
    "        # for background, make expanded sized windows directly (1000 instead of usual 200)\n",
    "        make_windows(tmp_regions, tmp_expanded_bkg_regions, \n",
    "                     bin_size=expanded_window_size, stride=expanded_window_size)     \n",
    "\n",
    "        # generate shrunk regions for labeling (using negative flank_size)\n",
    "        tmp_bkg_regions = tmpDir + \"_tmp_bkg_regions.tsv\"\n",
    "        os.system(\"bedtools slop -i \" + tmp_expanded_bkg_regions + \" -g \" + \\\n",
    "            chrom_sizes_fn + \" -b \" + str(-flank_size) + \" > \" + tmp_bkg_regions)\n",
    "\n",
    "        os.system(\"cat \" + tmp_core_regions + \" >> \" + tmp_bkg_regions)\n",
    "\n",
    "        cmd = \"cat \" + tmp_bkg_regions + \" | bedtools sort | uniq -u > \" + tmp_regions\n",
    "        os.system(cmd)\n",
    "\n",
    "    return tmp_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_regions_multitask(labels_multitask, chrom_sizes_fn, positives, \n",
    "                            ambiguous = None, regions = None,\n",
    "                            bin_size=200, flank_size=400, stride=50,\n",
    "                            n_jobs=1, genome='hg19',\n",
    "                            min_bin_distance_to_chrom_edge=5000):\n",
    "    ''' \n",
    "    generate labels for multitask training\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels_multitask : output labels file.\n",
    "    chrom_sizes_fn   : file that contains the sizes of reference genomes.\n",
    "    positives        : the true positives, a list of paths, one for each experiment,\n",
    "                       mandatory.\n",
    "    ambiguous        : the ambiguous set, a list of paths, one for each experiment,\n",
    "                       optional. if present, must have the same length as the \n",
    "                       positives, so that we can match ambiguous to the positives\n",
    "    regions          : (not supported yet) \n",
    "                       total regions being labeled. If not specified, \n",
    "                       use the union of positives\n",
    "    '''\n",
    "    #os.system(\"mkdir -p \" + tmpDir)\n",
    "\n",
    "    logging.debug(\"bin-size=%d, stride=%d\" % (bin_size, stride))\n",
    "    load_chrom_sizes(chrom_sizes_fn)\n",
    "\n",
    "    pos_unzips, amb_unzips = unzip_peaks(positives, ambiguous)\n",
    "\n",
    "    \n",
    "    # sort and merge the positives \n",
    "    tmp_pos_regions = tmpDir + \"_tmp_pos_regions.tsv\"\n",
    "    cmd = \"cat \" + \" \".join(pos_unzips) + \\\n",
    "        \" | cut -f 1-3 | bedtools sort | bedtools merge > \" + tmp_pos_regions\n",
    "    os.system(cmd)\n",
    "\n",
    "    # unify the core region lengths to multiple of strides and make windows\n",
    "    tmp_core_regions = tmpDir + \"_tmp_core_regions.tsv\"\n",
    "    make_windows(tmp_pos_regions, tmp_core_regions, bin_size=bin_size, stride=stride)     \n",
    "\n",
    "    tmp_regions = handle_background_intervals(regions, tmp_core_regions, chrom_sizes_fn, \n",
    "                                              bin_size=bin_size, flank_size=flank_size)\n",
    "\n",
    "    logging.info(\"LABEL_REGIONS sort merge done\")\n",
    "\n",
    "    # generate positive and ambigous intersects\n",
    "    pos_intersects, amb_intersects = gen_intersects(pos_unzips, amb_unzips, tmp_regions)\n",
    "\n",
    "    # generate expanded regions for added context\n",
    "    tmp_expanded_regions = tmpDir + \"_tmp_expanded_regions.tsv\"\n",
    "    os.system(\"bedtools slop -i \" + tmp_regions + \" -g \" + \\\n",
    "        chrom_sizes_fn + \" -b \" + str(flank_size) + \" > \" + tmp_expanded_regions)\n",
    "\n",
    "    logging.info(\"LABEL_REGIONS intersect done\")\n",
    "\n",
    "    # label regions for each task and paste to the regions\n",
    "    for i in range(len(positives)):\n",
    "        tmp_labels = tmpDir + \"_tmp_labels_\" + str(i) + \".tsv\"\n",
    "        if ambiguous:\n",
    "            a_intersect = amb_intersects[i]\n",
    "        else:\n",
    "            a_intersect = None\n",
    "        label_regions_fast(tmp_regions, pos_intersects[i], a_intersect, tmp_labels)\n",
    "        tmp_paste = tmpDir + \"_tmp_paste\"\n",
    "        os.system(\"paste \" + tmp_expanded_regions + \" \" + tmp_labels + \" > \" + tmp_paste)\n",
    "        os.system(\"mv -f \" + tmp_paste + \" \" + tmp_expanded_regions)\n",
    "\n",
    "    logging.info(\"LABEL_REGIONS labels done\")\n",
    "    # shuffle the lines\n",
    "    os.system(\"shuf \" + tmp_expanded_regions + \" | pigz > \" + labels_multitask)\n",
    "\n",
    "    logging.info(\"LABEL_REGIONS ALL DONE *****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_label_regions_from_args():\n",
    "    args = parse_args()\n",
    "    if args.positives is not None: # and args.background is not None:\n",
    "        positives = args.positives.split(',')\n",
    "        if args.ambiguous is not None:\n",
    "            ambiguous = args.ambiguous.split(',')\n",
    "            assert len(ambiguous) == len(positives)\n",
    "        else:\n",
    "            ambiguous = None\n",
    "        path_to_dataset_intervals_file = os.path.abspath(\"{}.intervals_file.tsv.gz\".format(args.prefix))\n",
    "        #print(path_to_dataset_intervals_file)\n",
    "        label_regions_multitask(path_to_dataset_intervals_file,\n",
    "                                genomeDir + \"hg19.chrom.sizes\", \n",
    "                                positives, ambiguous=ambiguous, regions=args.background, \n",
    "                                bin_size=args.bin_size, flank_size=args.flank_size, \n",
    "                                stride=args.stride, genome=args.genome, n_jobs=args.n_jobs)\n",
    "    else:\n",
    "        raise RuntimeError(\"Must pass in positives, background, and task names!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# guarantee to clean up tmp dir\n",
    "import contextlib\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def make_temp_directory():\n",
    "    temp_dir = tempfile.mkdtemp(dir = \".\", prefix = \"_tmp_\")\n",
    "    try:\n",
    "        yield temp_dir\n",
    "    finally:\n",
    "        shutil.rmtree(temp_dir)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with make_temp_directory() as temp_dir:\n",
    "        global tmpDir\n",
    "        tmpDir = temp_dir + \"/\"\n",
    "        run_label_regions_from_args()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
