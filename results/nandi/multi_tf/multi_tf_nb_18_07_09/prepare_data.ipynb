{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The directory layout is defined here, as relative path are used sometimes.\n",
    "\n",
    "$TFNET_ROOT is set to the root of TFNET dir\n",
    " /-- scripts       such as label_region, prepare_data.py, run_deeplift.py, run_modisco.py, run_pipeline.py etc\n",
    " /-- genome        hg19.fa hg19.chrom.sizes hg19.tsv\n",
    " /-- ENCODE_data   peak files downloaded from ENCODE project\n",
    " /-- results       results\n",
    "      |\n",
    "      /-- nandi----/-- multi_tf --/-- multi_tf_nb_18_07_09/ We are here!\n",
    "      |            /-- ZNF143\n",
    "      |\n",
    "      /-- nautilus-/-- CTCF\n",
    "      |            /-- ZFX\n",
    "      |\n",
    "      /-- templates/-- config\n",
    "'''\n",
    "import os\n",
    "from os.path import basename\n",
    "\n",
    "ROOT_DIR   = os.getenv('TFNET_ROOT', \"../../\") \n",
    "scriptDir  = ROOT_DIR + \"/scripts/\"\n",
    "dataDir    = ROOT_DIR + \"/ENCODE_data/\"\n",
    "genomeDir  = ROOT_DIR + \"/genome/\"\n",
    "resultsDir = \"./\"\n",
    "logDir     = resultsDir + \"log/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "        format='%(asctime)s %(levelname)-5s %(message)s',\n",
    "        level=logging.DEBUG,\n",
    "        datefmt='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_task_list(task_list, add_bg):\n",
    "    header = \"id\"\n",
    "    tmp_empty_file = \"/dev/null\"\n",
    "\n",
    "    positives = []\n",
    "    ambiguous = []\n",
    "\n",
    "    # [tf, cell type, experiment, rep state] in task_list\n",
    "    for tf, cell, exp, rep in task_list:\n",
    "        positive = dataDir + cell + \"-\" + tf + \"-human-\" + exp + \"-optimal_idr.narrowPeak.gz\"\n",
    "        positives.append(positive)\n",
    "        \n",
    "        header += \"\\t\" + exp\n",
    "        \n",
    "        merged = tmp_empty_file\n",
    "        # merged = \"\"\n",
    "        if rep == 1: # bit0 == 1, has rep1\n",
    "            rep1 = cell + \"-\" + tf + \"-human-\" + exp + \"-rep1.narrowPeak.gz\"\n",
    "            merged = dataDir+rep1\n",
    "        if rep == 2: # bit1 == 1, has rep2\n",
    "            rep2 = cell + \"-\" + tf + \"-human-\" + exp + \"-rep2.narrowPeak.gz\"\n",
    "            merged = dataDir+rep2\n",
    "        if rep == 3: # bit1,bit2 == 1, has both rep1 and rep2\n",
    "            rep1 = cell + \"-\" + tf + \"-human-\" + exp + \"-rep1.narrowPeak.gz\"\n",
    "            rep2 = cell + \"-\" + tf + \"-human-\" + exp + \"-rep2.narrowPeak.gz\"\n",
    "            tmp_merged = tmpDir + \"_tmp_\" + cell + \"-\" + tf + \"-human-\" + exp + \"-merged.narrowPeak.gz\"\n",
    "            merged = tmp_merged\n",
    "            os.system(\"pigz -d -c \" + dataDir+rep1 + \" \" + dataDir+rep2 + \\\n",
    "                      \" | cut -f 1-3 | bedtools sort | bedtools merge | pigz -c > \" + merged)\n",
    "        ambiguous.append(merged)\n",
    "\n",
    "    if positives != []:\n",
    "        positives_str = \" --positives \" + ','.join(positives)\n",
    "    else:\n",
    "        positives_str = \"\"\n",
    "\n",
    "    if ambiguous != []:\n",
    "        ambiguous_str = \" --ambiguous \" + ','.join(ambiguous)\n",
    "    else:\n",
    "        ambiguous_str = \"\"\n",
    "    \n",
    "    background_str = \" --background \" + genomeDir + \"hg19.tsv \"\n",
    "\n",
    "    # call tfdragonn labelregions\n",
    "    #\n",
    "    # labels_multitask_gz = \"tflabel.intervals_file.tsv.gz\"\n",
    "    # cmd = \"tfdragonn labelregions \" + positives_str + ambiguous_str + \\\n",
    "    #       \" --genome hg19 --prefix tflabel\" #       + \" --background background \"\n",
    "\n",
    "    labels_multitask_gz = \"label.intervals_file.tsv.gz\"\n",
    "    cmd = scriptDir + \"label_regions \" + positives_str + ambiguous_str + \\\n",
    "          \" --genome hg19 --prefix label \" + \" --stride 20\"\n",
    "    if add_bg:\n",
    "         cmd = cmd + background_str\n",
    "    logging.debug(cmd)\n",
    "    os.system(cmd)\n",
    "\n",
    "    labels_multitask    = labels_multitask_gz[:-3]\n",
    "\n",
    "    os.system(\"pigz -d -c \" + labels_multitask_gz +  \" > \" + labels_multitask)\n",
    "\n",
    "    tmp_labels_wo_title = tmpDir + \"_tmp_labels_without_title.txt\"\n",
    "\n",
    "    # use sed to change each line from\n",
    "    # chr<\\t>start<\\t>end<\\t>label1<\\t>label2 ...\n",
    "    # to \n",
    "    # chr:start-end<\\t>label1<\\t>label2 ...\n",
    "    os.system(\"cat \" + labels_multitask + \" | sed 's/\\t/:/; s/\\t/-/' > \" + tmp_labels_wo_title)\n",
    "\n",
    "    os.system(\"bedtools getfasta -fi \" + genomeDir + \"hg19.fa -bed \" + labels_multitask + \" -fo inputs.fa\")\n",
    "\n",
    "    #make the final inputs labels files from the shuffled lines (tfdragonn shuffles already)\n",
    "    os.system(\"echo \" + header + \" > labels.txt\")\n",
    "    os.system(\"cat \" + tmp_labels_wo_title + \" >> labels.txt\")\n",
    "\n",
    "    logging.info(\"split and make hdf5\")\n",
    "    os.system(\"mkdir -p splits\")\n",
    "\n",
    "    #make the splits\n",
    "    valid_chrom = \"chr2\" # chr2 is used for validation\n",
    "    test_chrom  = \"chr1\" # chr1 is used for testing\n",
    "\n",
    "    os.system(\"cat labels.txt | grep \" + valid_chrom + \": | pigz -c > splits/valid.txt.gz\")\n",
    "    os.system(\"cat labels.txt | grep \" + test_chrom  + \": | pigz -c > splits/test.txt.gz\")\n",
    "    cmd = \"cat labels.txt | grep -v \\\"\" + test_chrom  + \":\\|\"+ valid_chrom + \":\\|^id\" + \"\\\" | pigz -c > splits/train.txt.gz\"\n",
    "    os.system(cmd)\n",
    "\n",
    "    os.system(\"pigz -f labels.txt\")\n",
    "    #os.system(\"pigz -f inputs.fa\")\n",
    "\n",
    "    os.system(\"make_hdf5 --yaml_configs make_hdf5_yaml/* --output_dir .\")\n",
    "\n",
    "    logging.info(\"prepare_data done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Syntax: ', '/home/ktian/anaconda3/envs/tfenv/lib/python2.7/site-packages/ipykernel_launcher.py', ' [--no-bg]')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 10:16:04 DEBUG /home/ktian/kundajelab/tfnet/scripts/label_regions  --positives /home/ktian/kundajelab/tfnet/ENCODE_data/GM12878-CTCF-human-ENCSR000AKB-optimal_idr.narrowPeak.gz,/home/ktian/kundajelab/tfnet/ENCODE_data/GM12878-SIX5-human-ENCSR000BJE-optimal_idr.narrowPeak.gz,/home/ktian/kundajelab/tfnet/ENCODE_data/GM12878-ZNF143-human-ENCSR000DZL-optimal_idr.narrowPeak.gz --ambiguous ./_tmp_qfMGWB/_tmp_GM12878-CTCF-human-ENCSR000AKB-merged.narrowPeak.gz,./_tmp_qfMGWB/_tmp_GM12878-SIX5-human-ENCSR000BJE-merged.narrowPeak.gz,./_tmp_qfMGWB/_tmp_GM12878-ZNF143-human-ENCSR000DZL-merged.narrowPeak.gz --genome hg19 --prefix label  --stride 20 --background /home/ktian/kundajelab/tfnet/genome/hg19.tsv \n",
      "2018-07-10 10:17:36 INFO  split and make hdf5\n",
      "2018-07-10 10:17:38 INFO  prepare_data done\n"
     ]
    }
   ],
   "source": [
    "# guarantee to clean up tmp dir\n",
    "import contextlib\n",
    "import tempfile\n",
    "import shutil\n",
    "@contextlib.contextmanager\n",
    "def make_temp_directory():\n",
    "    temp_dir = tempfile.mkdtemp(dir = \".\", prefix = \"_tmp_\")\n",
    "    try:\n",
    "        yield temp_dir\n",
    "    finally:\n",
    "        shutil.rmtree(temp_dir)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    import sys\n",
    "\n",
    "    if len(sys.argv) > 2:\n",
    "        print(\"Syntax: \", sys.argv[0] , \" [--no-bg]\")\n",
    "        quit()\n",
    "\n",
    "    if len(sys.argv) == 2 and sys.argv[1] == \"--no-bg\":\n",
    "        add_bg = False\n",
    "    else:\n",
    "        add_bg = True\n",
    "\n",
    "    task_list = [['CTCF',  'GM12878','ENCSR000AKB',3], # CTCF\n",
    "                 ['SIX5',  'GM12878','ENCSR000BJE',3], # SIX5\n",
    "                 ['ZNF143','GM12878','ENCSR000DZL',3]  # ZNF143\n",
    "                ]\n",
    "\n",
    "    with make_temp_directory() as temp_dir:\n",
    "        global tmpDir\n",
    "        tmpDir = temp_dir + \"/\"\n",
    "        process_task_list(task_list, add_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3535075, 3)\n",
      "                         ENCSR000AKB  ENCSR000BJE  ENCSR000DZL\n",
      "id                                                            \n",
      "chr14:92178000-92179000            0            0            0\n",
      "chrY:52392000-52393000             0            0            0\n",
      "chr16:14824000-14825000            0            0            0\n",
      "chr14:63851000-63852000            0            0            0\n",
      "chr13:69038000-69039000            0            0            0\n",
      "Task         count\n",
      "ENCSR000AKB  -1        157857\n",
      "              0       3019148\n",
      "              1        358070\n",
      "ENCSR000BJE  -1        230535\n",
      "              0       3275670\n",
      "              1         28870\n",
      "ENCSR000DZL  -1        164586\n",
      "              0       3073438\n",
      "              1        297051\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"labels.txt.gz\", sep='\\t', index_col=0, header=0, compression='gzip')\n",
    "print(df.shape)\n",
    "\n",
    "print(df.head(5))\n",
    "\n",
    "#df.sum(axis=0)\n",
    "\n",
    "melted_data = pd.melt(df, value_vars=['ENCSR000AKB', 'ENCSR000BJE','ENCSR000DZL'], \n",
    "                      var_name='Task', value_name='count')\n",
    "print(melted_data.groupby(by=['Task', 'count'])['count'].count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
